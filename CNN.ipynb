{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Convolutional Neural Network - Pattern Recognition in Stock Markets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "#import pandas_datareader as pdr\n",
    "import csv\n",
    "import warnings\n",
    "from keras import layers\n",
    "from keras import models\n",
    "\n",
    "\n",
    "N = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "#hide all warnings\n",
    "#warnings.filterwarnings('ignore')\n",
    "\n",
    "#show all warnings just once\n",
    "warnings.filterwarnings(action='once')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from helpers import delete_nans, get_returns, plot_example_returns, tickers, get_data_subsets#, data_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "begin = \"2007-01-01\"\n",
    "finish = \"2017-01-01\"\n",
    "\n",
    "#data_loader(begin, finish, 'returns.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "returns = get_returns('returns.csv', N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_nans('returns.csv', 'returns.csv')\n",
    "plot_example_returns('returns.csv', N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn(x_train, y_train, x_test, y_test, inp_shape):\n",
    "    verbose, epochs, batch_size = 1, 40, 50 \n",
    "    \"\"\"\n",
    "    verbose: 0-kein output, 1-ladebalken, 2-epochenzahlen printen\n",
    "    batch_size: Nicht definieren (https://stackoverflow.com/questions/44747343/keras-input-explanation-input-shape-units-batch-size-dim-etc)\n",
    "    epochs: Anzahl Iterationen durch das Trainingsset\n",
    "    \"\"\"\n",
    "    \n",
    "    N = inp_shape[1]\n",
    "    #init\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv1D(filters=64, kernel_size=3, activation='relu',\n",
    "                     input_shape=inp_shape))\n",
    "    model.add(layers.Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "    #Conv1D => 1D Convolution (Schaut nach Mustern)\n",
    "    #mit filters = Anzahl Weight Functions, kernel_size = Anzahl simultan betrachteter Felder, \n",
    "    #relu = 0 für value<0 sonst linear\n",
    "    \n",
    "    model.add(layers.Dropout(0.3))\n",
    "    #Dropout sets randomly chosen values to 0 to prevent overfitting\n",
    "    \n",
    "    model.add(layers.MaxPooling1D(pool_size=2))\n",
    "    #MaxPooling halbiert array Größe und nimmt größte Werte der Feature-Gewichtungen \n",
    "    \n",
    "    model.add(layers.Flatten())\n",
    "    #Flatten reduziert dimensionen eines arrays auf niedrigst mögliche Dimension (1xdim) (überschreibt Nullen))\n",
    "    \n",
    "    model.add(layers.Dense(100, activation='relu'))\n",
    "    model.add(layers.Dense(N, activation='linear'))\n",
    "    #Klassisches NN hinter Convolutional Layer geschaltet, lernt also im Feature Raum, durch Convolutional Net vorgebenen\n",
    "    \n",
    "    model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse', 'mae']) \n",
    "    #mean_squared_error (mse) and mean_absolute_error (mae)\n",
    "    \n",
    "    #fit network\n",
    "    model.fit(x_train,y_train, epochs=epochs, #batch_size=batch_size, \n",
    "              verbose=verbose)\n",
    "    #evaluate model\n",
    "    \n",
    "    #Print error values for classification of goodness\n",
    "    mse,mse2,mae = model.evaluate(x_test,y_test, batch_size=batch_size, verbose=verbose)\n",
    "    print(mse)\n",
    "    print(mse2)\n",
    "    print(mae)\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fully(x_train,y_train,x_test,y_test,inp_shape):\n",
    "    verbose, epochs, batch_size = 1, 40, 50 \n",
    "    \"\"\"\n",
    "    verbose: 0-kein output, 1-ladebalken, 2-epochenzahlen printen\n",
    "    batch_size: Nicht definieren (https://stackoverflow.com/questions/44747343/keras-input-explanation-input-shape-units-batch-size-dim-etc)\n",
    "    epochs: Anzahl Iterationen durch das Trainingsset\n",
    "    \"\"\"\n",
    "    \n",
    "    N = inp_shape[1]\n",
    "    #init\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(100, activation='tanh'))\n",
    "    model.add(layers.Dense(100, activation='relu'))\n",
    "    model.add(layers.Dropout(.5))\n",
    "    model.add(layers.Dense(100, activation='tanh'))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(100, activation='relu'))\n",
    "    model.add(layers.Dense(N, activation='linear'))\n",
    "    \n",
    "    model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse', 'mae']) \n",
    "    #mean_squared_error (mse) and mean_absolute_error (mae)\n",
    "    \n",
    "    #fit network\n",
    "    model.fit(x_train,y_train, epochs=epochs, #batch_size=batch_size, \n",
    "              verbose=verbose)\n",
    "    #evaluate model\n",
    "    \n",
    "    #Print error values for classification of goodness\n",
    "    mse,mse2,mae = model.evaluate(x_test,y_test, batch_size=batch_size, verbose=verbose)\n",
    "    print(mse)\n",
    "    print(mse2)\n",
    "    print(mae)\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn(x_train, y_train, x_test, y_test, inp_shape):\n",
    "    verbose, epochs, batch_size = 1, 40, 50 \n",
    "    \"\"\"\n",
    "    verbose: 0-kein output, 1-ladebalken, 2-epochenzahlen printen\n",
    "    batch_size: Nicht definieren (https://stackoverflow.com/questions/44747343/keras-input-explanation-input-shape-units-batch-size-dim-etc)\n",
    "    epochs: Anzahl Iterationen durch das Trainingsset\n",
    "    \"\"\"\n",
    "    \n",
    "    N = inp_shape[1]\n",
    "    #init\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.GRU(42, input_shape = inp_shape, return_sequences = True))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.GRU(42, return_sequences = False))\n",
    "    \n",
    "    #Dropout sets randomly chosen values to 0 to prevent overfitting\n",
    "    \n",
    "    #model.add(layers.MaxPooling1D(pool_size=2))\n",
    "    #MaxPooling halbiert array Größe und nimmt größte Werte der Feature-Gewichtungen \n",
    "    \n",
    "    #model.add(layers.Flatten())\n",
    "    #Flatten reduziert dimensionen eines arrays auf niedrigst mögliche Dimension (1xdim) (überschreibt Nullen))\n",
    "    \n",
    "    model.add(layers.Dense(100, activation='relu'))\n",
    "    model.add(layers.Dense(N, activation='linear'))\n",
    "    #Klassisches NN hinter Convolutional Layer geschaltet, lernt also im Feature Raum, durch Convolutional Net vorgebenen\n",
    "    \n",
    "    model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse', 'mae']) \n",
    "    #mean_squared_error (mse) and mean_absolute_error (mae)\n",
    "    \n",
    "    #fit network\n",
    "    model.fit(x_train,y_train, epochs=epochs, #batch_size=batch_size, \n",
    "              verbose=verbose)\n",
    "    #evaluate model\n",
    "    \n",
    "    #Print error values for classification of goodness\n",
    "    mse,mse2,mae = model.evaluate(x_test,y_test, batch_size=batch_size, verbose=verbose)\n",
    "    print(mse)\n",
    "    print(mse2)\n",
    "    print(mae)\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Funktion get_data_subsets unterteilt die Matrix in eine Matrix der Dimension dur x N (Zeitfenster x Stocks) und korrespondierender Vektor für den Tag darauf (dur=1 x stocks). Jedes Matrix-Vektor Paar stellt einen Input plus Target Output(Label, Lösung) dar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(input_df, dur, limit):\n",
    "    \"\"\"\n",
    "    input_df    die Input Matrix (duh)\n",
    "    dur         Zeitfenster\n",
    "    limit       Grenze für Train Test Split\n",
    "    \"\"\"\n",
    "\n",
    "    N = input_df.shape[1]\n",
    "    D = input_df.shape[0]\n",
    "    train = input_df.iloc[:limit,:]\n",
    "    test = input_df.iloc[limit-dur:,:]\n",
    "    x_train,y_train = get_data_subsets(train, dur) \n",
    "    x_test,y_test = get_data_subsets(test, dur)\n",
    "    inp_shape = (x_train.shape[1],N)\n",
    "    \n",
    "    \"\"\"für Dimensions-tests\"\"\"\n",
    "    print('x-train shape: ' + str(x_train.shape))\n",
    "    print('y-train shape: ' + str(y_train.shape))\n",
    "    print('x-test shape: ' + str(x_test.shape))\n",
    "    print('y-test shape: ' + str(y_test.shape))\n",
    "    print('test shape: ' + str(test.shape))\n",
    "    \n",
    "    model = cnn(x_train, y_train, x_test, y_test, inp_shape)\n",
    "    return model,x_train,y_train,x_test,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_fully_connected(input_df, dur, limit):\n",
    "    \"\"\"\n",
    "    input_df    die Input Matrix (duh)\n",
    "    dur         Zeitfenster\n",
    "    limit       Grenze für Train Test Split\n",
    "    \"\"\"\n",
    "\n",
    "    N = input_df.shape[1]\n",
    "    D = input_df.shape[0]\n",
    "    train = input_df.iloc[:limit,:]\n",
    "    test = input_df.iloc[limit-dur:,:]\n",
    "    print(\"now\")\n",
    "    x_train,y_train = get_data_subsets(train, dur) \n",
    "    x_test,y_test = get_data_subsets(test, dur)\n",
    "    inp_shape = (x_train.shape[1],N)\n",
    "    \n",
    "    \"\"\"für Dimensions-tests\"\"\"\n",
    "    print('x-train shape: ' + str(x_train.shape))\n",
    "    print('y-train shape: ' + str(y_train.shape))\n",
    "    print('x-test shape: ' + str(x_test.shape))\n",
    "    print('y-test shape: ' + str(y_test.shape))\n",
    "    print('test shape: ' + str(test.shape))\n",
    "    \n",
    "    model = fully(x_train, y_train, x_test, y_test, inp_shape)\n",
    "    return model,x_train,y_train,x_test,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_rnn(input_df, dur, limit):\n",
    "    \"\"\"\n",
    "    input_df    die Input Matrix (duh)\n",
    "    dur         Zeitfenster\n",
    "    limit       Grenze für Train Test Split\n",
    "    \"\"\"\n",
    "\n",
    "    N = input_df.shape[1]\n",
    "    D = input_df.shape[0]\n",
    "    train = input_df.iloc[:limit,:]\n",
    "    test = input_df.iloc[limit-dur:,:]\n",
    "    x_train,y_train = get_data_subsets(train, dur) \n",
    "    x_test,y_test = get_data_subsets(test, dur)\n",
    "    inp_shape = (x_train.shape[1],N)\n",
    "    \n",
    "    \"\"\"für Dimensions-tests\"\"\"\n",
    "    print('x-train shape: ' + str(x_train.shape))\n",
    "    print('y-train shape: ' + str(y_train.shape))\n",
    "    print('x-test shape: ' + str(x_test.shape))\n",
    "    print('y-test shape: ' + str(y_test.shape))\n",
    "    print('test shape: ' + str(test.shape))\n",
    "    \n",
    "    model = rnn(x_train, y_train, x_test, y_test, inp_shape)\n",
    "    return model,x_train,y_train,x_test,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1900\n",
      "518\n",
      "x-train shape: (1900, 109, 20)\n",
      "y-train shape: (1900, 20)\n",
      "x-test shape: (518, 109, 20)\n",
      "y-test shape: (518, 20)\n",
      "test shape: (618, 20)\n",
      "Epoch 1/40\n",
      "1900/1900 [==============================] - 16s 8ms/step - loss: 4.1667e-04 - mse: 4.1667e-04 - mae: 0.0122\n",
      "Epoch 2/40\n",
      "1900/1900 [==============================] - 15s 8ms/step - loss: 4.1305e-04 - mse: 4.1305e-04 - mae: 0.0121\n",
      "Epoch 3/40\n",
      "1900/1900 [==============================] - 15s 8ms/step - loss: 4.1247e-04 - mse: 4.1247e-04 - mae: 0.0121\n",
      "Epoch 4/40\n",
      "1900/1900 [==============================] - 15s 8ms/step - loss: 4.1261e-04 - mse: 4.1261e-04 - mae: 0.0121\n",
      "Epoch 5/40\n",
      "1900/1900 [==============================] - 15s 8ms/step - loss: 4.1293e-04 - mse: 4.1293e-04 - mae: 0.0122\n",
      "Epoch 6/40\n",
      "1900/1900 [==============================] - 15s 8ms/step - loss: 4.1242e-04 - mse: 4.1242e-04 - mae: 0.0121\n",
      "Epoch 7/40\n",
      "1900/1900 [==============================] - 15s 8ms/step - loss: 4.1034e-04 - mse: 4.1034e-04 - mae: 0.0121\n",
      "Epoch 8/40\n",
      "1900/1900 [==============================] - 16s 8ms/step - loss: 4.0995e-04 - mse: 4.0995e-04 - mae: 0.0121\n",
      "Epoch 9/40\n",
      "1900/1900 [==============================] - 15s 8ms/step - loss: 4.1018e-04 - mse: 4.1018e-04 - mae: 0.0121\n",
      "Epoch 10/40\n",
      "1900/1900 [==============================] - 16s 8ms/step - loss: 4.0901e-04 - mse: 4.0901e-04 - mae: 0.0121\n",
      "Epoch 11/40\n",
      "1900/1900 [==============================] - 15s 8ms/step - loss: 4.0807e-04 - mse: 4.0807e-04 - mae: 0.0121\n",
      "Epoch 12/40\n",
      "1900/1900 [==============================] - 16s 8ms/step - loss: 4.0654e-04 - mse: 4.0654e-04 - mae: 0.0120\n",
      "Epoch 13/40\n",
      "1900/1900 [==============================] - 17s 9ms/step - loss: 4.0694e-04 - mse: 4.0694e-04 - mae: 0.0121\n",
      "Epoch 14/40\n",
      "1900/1900 [==============================] - 18s 9ms/step - loss: 4.0544e-04 - mse: 4.0544e-04 - mae: 0.0121\n",
      "Epoch 15/40\n",
      "1900/1900 [==============================] - 17s 9ms/step - loss: 4.0279e-04 - mse: 4.0279e-04 - mae: 0.0121\n",
      "Epoch 16/40\n",
      "1900/1900 [==============================] - 16s 9ms/step - loss: 4.0426e-04 - mse: 4.0426e-04 - mae: 0.0120\n",
      "Epoch 17/40\n",
      "1900/1900 [==============================] - 16s 9ms/step - loss: 4.0368e-04 - mse: 4.0368e-04 - mae: 0.0121\n",
      "Epoch 18/40\n",
      "1900/1900 [==============================] - 18s 10ms/step - loss: 4.0091e-04 - mse: 4.0091e-04 - mae: 0.0120\n",
      "Epoch 19/40\n",
      "1900/1900 [==============================] - 16s 9ms/step - loss: 3.9716e-04 - mse: 3.9716e-04 - mae: 0.0120\n",
      "Epoch 20/40\n",
      "1900/1900 [==============================] - 17s 9ms/step - loss: 3.9994e-04 - mse: 3.9994e-04 - mae: 0.0120\n",
      "Epoch 21/40\n",
      "1900/1900 [==============================] - 15s 8ms/step - loss: 3.9519e-04 - mse: 3.9519e-04 - mae: 0.0119\n",
      "Epoch 22/40\n",
      "1900/1900 [==============================] - 17s 9ms/step - loss: 3.9418e-04 - mse: 3.9418e-04 - mae: 0.0119\n",
      "Epoch 23/40\n",
      " 416/1900 [=====>........................] - ETA: 12s - loss: 3.9209e-04 - mse: 3.9209e-04 - mae: 0.0119"
     ]
    }
   ],
   "source": [
    "model_rnn,x_train,y_train,x_test,y_test = main_rnn(returns, 100, 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1900\n",
      "518\n",
      "x-train shape: (1900, 109, 20)\n",
      "y-train shape: (1900, 20)\n",
      "x-test shape: (518, 109, 20)\n",
      "y-test shape: (518, 20)\n",
      "test shape: (618, 20)\n",
      "Epoch 1/40\n",
      "1900/1900 [==============================] - 2s 1ms/step - loss: 5.4347e-04 - mse: 5.4347e-04 - mae: 0.0140\n",
      "Epoch 2/40\n",
      "1900/1900 [==============================] - 2s 899us/step - loss: 4.1261e-04 - mse: 4.1261e-04 - mae: 0.0120\n",
      "Epoch 3/40\n",
      "1900/1900 [==============================] - 2s 920us/step - loss: 4.1285e-04 - mse: 4.1285e-04 - mae: 0.0120\n",
      "Epoch 4/40\n",
      "1900/1900 [==============================] - 2s 879us/step - loss: 4.1273e-04 - mse: 4.1273e-04 - mae: 0.0119\n",
      "Epoch 5/40\n",
      "1900/1900 [==============================] - 2s 867us/step - loss: 4.1291e-04 - mse: 4.1291e-04 - mae: 0.0120\n",
      "Epoch 6/40\n",
      "1900/1900 [==============================] - 2s 970us/step - loss: 4.1358e-04 - mse: 4.1358e-04 - mae: 0.0120\n",
      "Epoch 7/40\n",
      "1900/1900 [==============================] - 2s 915us/step - loss: 4.1317e-04 - mse: 4.1317e-04 - mae: 0.0120\n",
      "Epoch 8/40\n",
      "1900/1900 [==============================] - 2s 879us/step - loss: 4.1323e-04 - mse: 4.1323e-04 - mae: 0.0120\n",
      "Epoch 9/40\n",
      "1900/1900 [==============================] - 2s 827us/step - loss: 4.1298e-04 - mse: 4.1298e-04 - mae: 0.0120\n",
      "Epoch 10/40\n",
      "1900/1900 [==============================] - 2s 832us/step - loss: 4.1342e-04 - mse: 4.1342e-04 - mae: 0.0120\n",
      "Epoch 11/40\n",
      "1900/1900 [==============================] - 2s 807us/step - loss: 4.1309e-04 - mse: 4.1309e-04 - mae: 0.0120 0s - loss: 3.9671e-04 - mse: 3.9671e-04  - ETA: 0s - loss: 4.0897e-04 - mse: 4.0897e-04 - mae: 0.\n",
      "Epoch 12/40\n",
      "1900/1900 [==============================] - 2s 924us/step - loss: 4.1325e-04 - mse: 4.1325e-04 - mae: 0.0120\n",
      "Epoch 13/40\n",
      "1900/1900 [==============================] - 2s 862us/step - loss: 4.1273e-04 - mse: 4.1273e-04 - mae: 0.0120\n",
      "Epoch 14/40\n",
      "1900/1900 [==============================] - 2s 889us/step - loss: 4.1382e-04 - mse: 4.1382e-04 - mae: 0.0120\n",
      "Epoch 15/40\n",
      "1900/1900 [==============================] - 2s 888us/step - loss: 4.1315e-04 - mse: 4.1315e-04 - mae: 0.0120\n",
      "Epoch 16/40\n",
      "1900/1900 [==============================] - 2s 940us/step - loss: 4.1314e-04 - mse: 4.1314e-04 - mae: 0.0120\n",
      "Epoch 17/40\n",
      "1900/1900 [==============================] - 2s 1ms/step - loss: 4.1355e-04 - mse: 4.1355e-04 - mae: 0.0120\n",
      "Epoch 18/40\n",
      "1900/1900 [==============================] - 2s 1ms/step - loss: 4.1263e-04 - mse: 4.1263e-04 - mae: 0.0120\n",
      "Epoch 19/40\n",
      "1900/1900 [==============================] - 2s 1ms/step - loss: 4.1324e-04 - mse: 4.1324e-04 - mae: 0.0120\n",
      "Epoch 20/40\n",
      "1900/1900 [==============================] - 2s 911us/step - loss: 4.1286e-04 - mse: 4.1286e-04 - mae: 0.0120\n",
      "Epoch 21/40\n",
      "1900/1900 [==============================] - 2s 943us/step - loss: 4.1379e-04 - mse: 4.1379e-04 - mae: 0.0120\n",
      "Epoch 22/40\n",
      "1900/1900 [==============================] - 2s 926us/step - loss: 4.1471e-04 - mse: 4.1471e-04 - mae: 0.0120\n",
      "Epoch 23/40\n",
      "1900/1900 [==============================] - 2s 886us/step - loss: 4.1324e-04 - mse: 4.1324e-04 - mae: 0.0120\n",
      "Epoch 24/40\n",
      "1900/1900 [==============================] - 2s 890us/step - loss: 4.1464e-04 - mse: 4.1464e-04 - mae: 0.0120\n",
      "Epoch 25/40\n",
      "1900/1900 [==============================] - 2s 916us/step - loss: 4.1339e-04 - mse: 4.1339e-04 - mae: 0.0120\n",
      "Epoch 26/40\n",
      "1900/1900 [==============================] - 2s 894us/step - loss: 4.1378e-04 - mse: 4.1378e-04 - mae: 0.0120\n",
      "Epoch 27/40\n",
      "1900/1900 [==============================] - 2s 923us/step - loss: 4.1353e-04 - mse: 4.1353e-04 - mae: 0.0120\n",
      "Epoch 28/40\n",
      "1900/1900 [==============================] - 2s 899us/step - loss: 4.1291e-04 - mse: 4.1291e-04 - mae: 0.0120\n",
      "Epoch 29/40\n",
      "1900/1900 [==============================] - 2s 908us/step - loss: 4.1354e-04 - mse: 4.1354e-04 - mae: 0.0120\n",
      "Epoch 30/40\n",
      "1900/1900 [==============================] - 2s 918us/step - loss: 4.1329e-04 - mse: 4.1329e-04 - mae: 0.0120\n",
      "Epoch 31/40\n",
      "1900/1900 [==============================] - 2s 902us/step - loss: 4.1299e-04 - mse: 4.1299e-04 - mae: 0.0120\n",
      "Epoch 32/40\n",
      "1900/1900 [==============================] - 2s 899us/step - loss: 4.1331e-04 - mse: 4.1331e-04 - mae: 0.0120\n",
      "Epoch 33/40\n",
      "1900/1900 [==============================] - 2s 921us/step - loss: 4.1291e-04 - mse: 4.1291e-04 - mae: 0.0120\n",
      "Epoch 34/40\n",
      "1900/1900 [==============================] - 2s 911us/step - loss: 4.1381e-04 - mse: 4.1381e-04 - mae: 0.0120\n",
      "Epoch 35/40\n",
      "1900/1900 [==============================] - 2s 913us/step - loss: 4.1323e-04 - mse: 4.1323e-04 - mae: 0.0120\n",
      "Epoch 36/40\n",
      "1900/1900 [==============================] - 2s 934us/step - loss: 4.1306e-04 - mse: 4.1306e-04 - mae: 0.0120\n",
      "Epoch 37/40\n",
      "1900/1900 [==============================] - 2s 920us/step - loss: 4.1352e-04 - mse: 4.1352e-04 - mae: 0.0120\n",
      "Epoch 38/40\n",
      "1900/1900 [==============================] - 2s 912us/step - loss: 4.1326e-04 - mse: 4.1326e-04 - mae: 0.0120\n",
      "Epoch 39/40\n",
      "1900/1900 [==============================] - 2s 984us/step - loss: 4.1351e-04 - mse: 4.1351e-04 - mae: 0.0120\n",
      "Epoch 40/40\n",
      "1900/1900 [==============================] - 2s 974us/step - loss: 4.1351e-04 - mse: 4.1351e-04 - mae: 0.0120\n",
      "518/518 [==============================] - 0s 386us/step\n",
      "0.0002865413074947095\n",
      "0.00028654129710048437\n",
      "0.01060516107827425\n"
     ]
    }
   ],
   "source": [
    "model_cnn,x_train,y_train,x_test,y_test = main(returns, 100, 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_fully,x_train,y_train,x_test,y_test = main_fully_connected(returns, 100, 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_fully.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_cnn.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_rnn.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to check wether stock value changes were recognised to increase/decrease correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def directional_goodness(model,x_new,y_new):\n",
    "    \"\"\"\n",
    "    directional goodnes gives the factor of correctly predicted signs of first order derivative of returns to false ones\n",
    "    oder auch: \n",
    "    gibt die Anzahl der Beobachtungen an, deren Vorhersage das richtige Vorzeichen hatte (Kurs steigt, Kurs fällt)\n",
    "    \"\"\"\n",
    "    y_pred = model.predict(x_new)\n",
    "    count = 0\n",
    "    #print(y_new.shape)\n",
    "    for i in range(len(y_pred)):\n",
    "        for j in range(len(y_pred[i])):\n",
    "            p= y_pred[i,j] > 0\n",
    "            n = y_new[i,j] > 0\n",
    "            if n==p:\n",
    "                count +=1\n",
    "    print('percentage of correctly predicted directions of returns: ' + str(count/len(y_pred)/len(y_pred[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directional_goodness(model_cnn,x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directional_goodness(model_cnn,x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directional_goodness(model_fully,x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directional_goodness(model_fully,x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directional_goodness(model_rnn,x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directional_goodness(model_rnn,x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to check internal goodness - predicted values vs actual measured values used for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def internal_goodness(model, x_new, y_new):\n",
    "    print('compare true to predicted values of internal validation on learned dataset: ')\n",
    "    y_pred = model.predict(x_new)\n",
    "    #model.predict nimmt x-werte und gibt die predicteten y-werte zurück\n",
    "    plt.scatter(y_new, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "internal_goodness(model_cnn,x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "internal_goodness(model_cnn,x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "internal_goodness(model_fully,x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "internal_goodness(model_fully,x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "internal_goodness(model_rnn,x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "internal_goodness(model_rnn,x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to check external goodness - predicted values for future data vs actual future data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def external_goodness(model, x_new, y_new):\n",
    "    print('compare true to predicted values of external validation set: ')\n",
    "    y_pred = model.predict(x_new)\n",
    "    color =  [\"r\", \"b\", \"g\"]\n",
    "    for i in range(3):\n",
    "        plt.plot(y_new[:100,i],c=color[i], label = 'true')\n",
    "        plt.plot(y_pred[:100,i], c=color[i], linestyle='--', label = 'pred')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "external_goodness(model_cnn,x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "external_goodness(model_cnn,x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "external_goodness(model_fully,x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "external_goodness(model_fully,x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "external_goodness(model_rnn,x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "external_goodness(model_rnn,x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test2 = x_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,20):\n",
    "    x_test2[:,:,i] = x_test[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "external_goodness(model_cnn, x_test2,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def largest(array, amount):\n",
    "    return array.argsort()[:,-amount:]\n",
    "\n",
    "\n",
    "def compare_top(model, x_test, y_test):\n",
    "    amount = 5\n",
    "    mean_all = np.mean(y_test)\n",
    "    y_pred = model.predict(x_test)\n",
    "    top_index = largest(y_pred,amount)\n",
    "    mean_mach = np.mean(y_test[top_index])\n",
    "    return mean_mach-mean_all\n",
    "compare_top(model, x_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
